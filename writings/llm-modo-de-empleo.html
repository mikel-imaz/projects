
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>LLM: modo de empleo &#8212; datuz</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-232XT3FYCT"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-232XT3FYCT');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-232XT3FYCT');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'writings/llm-modo-de-empleo';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="icon" href="../_static/logo.svg"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Ley de IA de la UE" href="ley-de-ia-de-la-ue.html" />
    <link rel="prev" title="IA aplicada: la empresa empoderada por la IA" href="ia-aplicada-la-empresa-empoderada-por-la-ia.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.svg" class="logo__image only-light" alt="datuz - Home"/>
    <img src="../_static/logo.svg" class="logo__image only-dark pst-js-only" alt="datuz - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Data science projects
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../projects_competition.html">Competition projects</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/machine-downtime.html">Predicting Industrial Machine Downtime</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/book-popularity.html">What makes a good book?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/internet-patterns.html">Analyzing global internet patterns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/sleepinc.html">Helping find a better sleep</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/hairloss.html">Hairloss Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/employee-network.html">Employee Network Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/hospital.html">Reducing hospital readmissions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/hotels.html">Predicting hotel cancellations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/webpage.html">Was a website redesign successful?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/segmentation.html">Improving customer segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/abalone.html">Seafood farm process improvement</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../projects_personal.html">Personal projects</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/chm.html">Canopy Height Map</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/moles.html">Mole monitoring</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/book-translation.html">Book translation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/p-antio-gpt.html">Sentiment analysis with embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/self-tracking.html">Self tracking</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/quakes.html">Earth Quakes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/climate.html">Climate Change</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/english-vocab.html">English Vocab</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/antio.html">Bar Reviews</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/ignatian.html">Ignatian Pilgrims</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/p-udalmap.html">Municipal Indicators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/p-films.html">Movie records</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/ages.html">Median Ages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/water.html">Water Supplies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/olele.html">Handfan Reviews</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/traffic_fines.html">Traffic Fines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/urban_trees.html">Urban Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/breads.html">Bread Prices</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Other</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../writings.html">Writings</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="la-importancia-de-adquirir-competencias-en-materia-de-datos.html">La importancia de adquirir competencias en materia de datos</a></li>
<li class="toctree-l2"><a class="reference internal" href="la-ciencia-de-convertir-los-datos-en-valor.html">La ciencia de convertir los datos en valor</a></li>
<li class="toctree-l2"><a class="reference internal" href="que-es-la-inteligencia-artificial.html">¿Qué es la Inteligencia Artificial?</a></li>
<li class="toctree-l2"><a class="reference internal" href="aprendizaje-autom%C3%A1tico-vs-programaci%C3%B3n-tradicional.html">Aprendizaje automático vs programación tradicional</a></li>
<li class="toctree-l2"><a class="reference internal" href="que-es-la-inteligencia-artificial-generativa.html">¿Qué es la Inteligencia Artificial Generativa?</a></li>
<li class="toctree-l2"><a class="reference internal" href="la-definicion-de-atributos-en-aprendizaje-automatico.html">La definición de atributos en aprendizaje automático</a></li>
<li class="toctree-l2"><a class="reference internal" href="por-que-python.html">¿Por qué Python?</a></li>
<li class="toctree-l2"><a class="reference internal" href="estadistica-computacional-la-estadistica-sin-dolor.html">Estadística computacional: la estadística sin dolor</a></li>
<li class="toctree-l2"><a class="reference internal" href="como-funciona-el-aprendizaje-profundo.html">¿Cómo funciona el aprendizaje profundo?</a></li>
<li class="toctree-l2"><a class="reference internal" href="ia-predictiva-vs-ia-generativa.html">IA predictiva vs IA generativa</a></li>
<li class="toctree-l2"><a class="reference internal" href="etica-en-la-ia.html">Ética en la IA</a></li>
<li class="toctree-l2"><a class="reference internal" href="las-3-capas-de-un-proyecto-de-datos.html">Las 3 capas de un proyecto de datos</a></li>
<li class="toctree-l2"><a class="reference internal" href="ia-aplicada-la-empresa-empoderada-por-la-ia.html">IA aplicada: la empresa empoderada por la IA</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">LLM: modo de empleo</a></li>
<li class="toctree-l2"><a class="reference internal" href="ley-de-ia-de-la-ue.html">Ley de IA de la UE</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../about-me.html">About me</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/mikel-imaz/projects" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/writings/llm-modo-de-empleo.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>LLM: modo de empleo</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelos-de-referencia">Modelos de referencia</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelos-adaptados-fine-tuning">Modelos adaptados: fine-tuning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelos-alimentados-retrieval-augmented-generation-rag">Modelos alimentados: Retrieval-Augmented Generation (RAG)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comparativa-entre-rag-y-fine-tuning">Comparativa entre RAG y fine-tuning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones">Conclusiones</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="llm-modo-de-empleo">
<h1>LLM: modo de empleo<a class="headerlink" href="#llm-modo-de-empleo" title="Link to this heading">#</a></h1>
<p><img alt="" src="../_images/toddler-3995508_640.jpg" /></p>
<p><svg version="1.1" width="1.0em" height="1.0em" class="sd-octicon sd-octicon-calendar" viewBox="0 0 16 16" aria-hidden="true"><path d="M4.75 0a.75.75 0 0 1 .75.75V2h5V.75a.75.75 0 0 1 1.5 0V2h1.25c.966 0 1.75.784 1.75 1.75v10.5A1.75 1.75 0 0 1 13.25 16H2.75A1.75 1.75 0 0 1 1 14.25V3.75C1 2.784 1.784 2 2.75 2H4V.75A.75.75 0 0 1 4.75 0ZM2.5 7.5v6.75c0 .138.112.25.25.25h10.5a.25.25 0 0 0 .25-.25V7.5Zm10.75-4H2.75a.25.25 0 0 0-.25.25V6h11V3.75a.25.25 0 0 0-.25-.25Z"></path></svg> 2024-10-19</p>
<p>Los <strong>LLM</strong> (<em>Large Language Model</em> → Modelo Grande de Lenguage) son los modelos que están detrás de la actual revolución de la <a class="reference external" href="https://datuz.es/2024/01/24/que-es-la-inteligencia-artificial-generativa/">IA generativa</a>. En esencia no dejan de ser modelos de <strong>aprendizaje automático</strong> basados en <strong>redes neuronales</strong> a gran escala, constituyendo lo que se conoce como <a class="reference external" href="https://datuz.es/2024/06/24/como-funciona-el-aprendizaje-profundo/">aprendizaje profundo o Deep Learning</a>. Con una arquitectura y algoritmia extraordinariamente complejas, son las estrellas del momento en el mundo de la <a class="reference external" href="https://datuz.es/2023/05/26/que-es-la-inteligencia-artificial/">Inteligencia Artificial</a>.</p>
<p>En las siglas LLM se encuentran las claves de su funcionalidad:</p>
<ul class="simple">
<li><p><strong>Modelos</strong> con una capacidad de inferir tal, que los lleva a generar contenido totalmente nuevo.</p></li>
<li><p><strong>Grandes</strong>, enormes modelos, constan de una cantidad inmensa de parámetros.</p></li>
<li><p><strong>Lenguaje</strong>: modelan y procesan el lenguaje humano.</p></li>
</ul>
<p>De manera que su <strong>componente creativa</strong>, unida a la posibilidad de establecer con estos sistemas una comunicación basada en el <strong>lenguaje natural</strong>, ha convertido a los LLM en referencia. Y los avances en sus prestaciones no dejan de sucederse como consecuencia de la carrera que han establecido las principales empresas del sector por hacerse con el dominio de esta tecnología y, por tanto, del mercado en el que se apoyan las herramientas de Inteligencia Artificial.</p>
<p> </p>
<p><img alt="" src="../_images/LLM-market.png" /></p>
<p> </p>
<section id="modelos-de-referencia">
<h2>Modelos de referencia<a class="headerlink" href="#modelos-de-referencia" title="Link to this heading">#</a></h2>
<p>Los LLM genéricos llevan a cabo su aprendizaje alimentándose de gigantescas cantidades de datos de internet. Durante este pantagruélico aprendizaje de base, conocido como <strong>pre-training</strong> (pre-entrenamiento), el sistema aprende por su cuenta patrones estadísticos del lenguaje. Los resultados mejoran cuantos más parámetros tenga el modelo (más grande es) y más datos de entrenamiento se le proporcionan.</p>
<p>El pre-entrenamiento es un proceso muy costoso, y solamente un reducido número de compañías pueden llevarlo a cabo. El acceso a grandes recursos computacionales como los que pueden ofrecer los principales proveedores de servicios en la nube (Amazon, Microsoft, Google) resulta fundamental en este sentido, y de ahí que estas empresas, junto con Meta, se hayan posicionado, directa o indirectamente, en primera línea en cuanto al desarrollo de estos modelos.</p>
<p>Como consecuencia se han presentado grandes LLMs orientados a desenvolverse en <strong>escenarios generalistas y versátiles</strong>. Sus colosales dimensiones (el último modelo de Meta tiene 405.000 millones de parámetros) les permiten capturar una gran amplitud y profundidad de conocimientos. Como, además de su entrenamiento, su empleo por parte del usuario también resulta costoso, los desarrolladores ofertan junto con ellos alternativas de menor tamaño que pueden resultar suficientes dependiendo de la aplicación (por ejemplo los modelos de Meta de 70.000 millones y el de 8.000 millones de parámetros). Estas versiones «mini» (como llama OpenAI a GPT-4o mini) derivan de los grandes <strong>modelos fundacionales</strong> mediante un procedimiento al que llaman <strong>distillation</strong> (destilación).</p>
<p> </p>
<p><img alt="" src="../_images/LLM-destilado.png" /></p>
<p> </p>
<p>Sin embargo, todos estos modelos generalistas suelen fallar en ciertos escenarios, por ejemplo cuando se les pide responder a cuestiones que requieren del manejo de información precisa y actualizada. Ello es debido a que durante su entrenamiento no han tenido acceso a dichas fuentes. En tales casos es posible que respondan de forma incorrecta o que divaguen con las conocidas alucinaciones. Por ello requieren ser ajustados para determinados usos.</p>
</section>
<section id="modelos-adaptados-fine-tuning">
<h2>Modelos adaptados: fine-tuning<a class="headerlink" href="#modelos-adaptados-fine-tuning" title="Link to this heading">#</a></h2>
<p>Los LLM presentan la posibilidad de reparametrizarse en cierto grado si se los somete a un nuevo entrenamiento al que se denomina <strong>fine-tuning</strong> (ajuste fino). Durante el mismo, el modelo pre-entrenado se somete a una nueva ronda de entrenamientos, pero esta vez absorbiendo un conjunto de datos específicos de cierto ámbito. De esta manera se logra un modelo mejor adaptado a las necesidades concretas del campo de aplicación en el que vaya a ser utilizado.</p>
<p> </p>
<p><img alt="" src="../_images/LLM-fine-tuning.png" /></p>
<p> </p>
<p>Por ejemplo, un modelo pre-entrenado puede ser bueno en una conversación sobre cuestiones generales, pero dará respuestas poco precisas o erróneas cuando se le pregunte por complejos procedimientos médicos o precedentes penales en el ámbito legal. Reentrenarlo con datos del campo médico o legal le permitirá responder a las preguntas de ese terreno con mayor precisión y coherencia.</p>
</section>
<section id="modelos-alimentados-retrieval-augmented-generation-rag">
<h2>Modelos alimentados: Retrieval-Augmented Generation (RAG)<a class="headerlink" href="#modelos-alimentados-retrieval-augmented-generation-rag" title="Link to this heading">#</a></h2>
<p>En la técnica llamada RAG, que se podría traducir por «generación mejorada por recuperación (de datos)», los LLM reciben <strong>información de contexto</strong> porque se les facilitan <strong>fuentes de datos externas al modelo</strong>. Dicha provisión de datos se produce en el mismo proceso de consulta: el usuario pregunta al modelo en el marco de un software preparado para tal función, el cual, en tiempo real, se encarga de buscar en una base de datos predefinida (que puede ser internet) la información que ayudará al LLM a dar una respuesta precisa. A continuación se trasladan al LLM las dos cosas: la consulta y la documentación que la acompaña.</p>
<p>La técnica RAG se vale de la <strong>ventana de contexto</strong> de la que disponen los LLM: la memoria de trabajo que emplean para mantener el historial de una conversación con un usuario. Actualmente, los modelos más avanzados contemplan una memoria de 128.000 tokens, que vendría a ser algo así como unas 80.000 palabras en inglés, el equivalente a una novela. Ello quiere decir que estarían preparados para contemplar la información contenida en una documentación equivalente a un libro. En cualquier caso, los programas que gestionan este trasvase de información son en sí mismos lo suficientemente eficientes como para seleccionar ellos mismos las piezas de información más relevantes para la consulta, empleando para ello técnicas de <strong>vectorización semántica</strong>.</p>
<p> </p>
<p><img alt="" src="../_images/LLM-RAG.png" /></p>
<p> </p>
<p>En resumidas cuentas, se podría ver un sistema de consulta RAG como el empleo del LLM como un mero robot conversacional que facilita la comunicación por lenguaje natural, ya que la información que aporta vendría, no tanto del conocimiento del modelo, sino de los datos que se le suministrarían durante la interacción.</p>
<p>La técnica de RAG podría ser combinada con un modelo que previamente haya sido sometido al ajuste fino, una solución que vendría a ser <strong>híbrida</strong>. El nombre que recibe dicho planteamiento es <strong>RAFT</strong> (Retrieval Augmented Fine-Tuning).</p>
</section>
<section id="comparativa-entre-rag-y-fine-tuning">
<h2>Comparativa entre RAG y fine-tuning<a class="headerlink" href="#comparativa-entre-rag-y-fine-tuning" title="Link to this heading">#</a></h2>
<p>¿Cuál de estas dos técnicas de ajuste es mejor? Depende del caso. A continuación se detallan sus diferencias atendiendo a varios aspectos.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>RAG</p></th>
<th class="head"><p>Fine-tuning</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Estilo de aprendizaje</p></td>
<td><p>Aprendizaje dinámico: Los modelos tienen acceso a la información más actualizada: internet, documentos, datos provistos por interfaces API, etc. Las respuestas generadas estarán actualizadas.</p></td>
<td><p>Aprendizaje estático: El modelo aprende a través de una nueva serie de datos durante el reentrenamiento. Permite adaptar sus respuestas al ámbito en cuestión, pero no puede integrar nueva información después de este aprendizaje sin que medie un nuevo entrenamiento.</p></td>
</tr>
<tr class="row-odd"><td><p>Adaptabilidad</p></td>
<td><p>Es mejor para generalizar. Emplea la información obtenida de diversas fuentes. RAG no cambia el estilo de la respuesta del modelo, solamente aporta información extra para guiar al modelo.</p></td>
<td><p>Personaliza la respuesta y mejora el rendimiento del LLM en el ámbito asociado al del entrenamiento recibido. Cambia el estilo de la respuesta generada y a veces proporciona respuestas más interesantes que RAG.</p></td>
</tr>
<tr class="row-even"><td><p>Recursos necesarios</p></td>
<td><p>Es bastante exigente en cuanto a recursos porque el proceso de aporte de información se produce en la misma consulta. Requiere por ello más memoria y recursos de computación.</p></td>
<td><p>Requiere también recursos, pero solo una vez, para el reentrenamiento: múltiples procesadores GPU y mucha memoria durante el aprendizaje, pero luego es bastante eficiente comparado con RAG.</p></td>
</tr>
<tr class="row-odd"><td><p>Coste</p></td>
<td><p>Requiere potentes LLM y buenos sistemas de vectorización semántica para generar buenas respuestas. Necesita también una base de datos vectorial rápida. Los costes operacionales pueden aumentar rápido.</p></td>
<td><p>Coste alto una vez, asociado al entrenamiento, pero después solamente se pagará por las respuestas inferidas, que son más baratas que las de un sistema RAG. De todas formas, por regla general y considerándolo todo, fine-tuning suele resultar más caro que RAG.</p></td>
</tr>
<tr class="row-even"><td><p>Complejidad de implementación</p></td>
<td><p>Puede ser implementado por ingenieros de software con una formación que es accesible en no mucho tiempo: sobre diseños de LLM, bases de datos vectoriales, embeddings (vectores semánticos).</p></td>
<td><p>Pide unos conocimientos de alto nivel en LLMs. Se necesitan años de experiencia en el campo del procesamiento del lenguaje natural para preparar la base de datos, ajustar los parámetros y monitorizar el comportamiento del modelo obtenido.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="conclusiones">
<h2>Conclusiones<a class="headerlink" href="#conclusiones" title="Link to this heading">#</a></h2>
<p>¿Qué método de ajuste emplear entonces? En muchos casos dependerá de los medios disponibles. Si el negocio es una startup con recursos limitados, entonces es mejor empezar por implementar RAG para comprobar que dicha solución da unos resultados satisfactorios (en lo que se conoce como una <strong>prueba de concepto</strong> o <strong>POC</strong>: Proof Of Concept), porque para ello se necesitarán competencias no demasiado exigentes.</p>
<p>Si se trata de una compañía de tamaño medio que quiere realizar el ajuste fino para mejorar la precisión de la respuesta e implementar el modelo en la nube, entonces tiene que contratar expertos como científicos de datos e ingenieros de machine learning. Fine-tuning requiere recursos computacionales muy exigentes, mucha memoria, conjuntos de datos de calidad y un equipo técnico conocedor de los LLM.</p>
<p>Una solución híbrida es aún más exigente, tanto en recursos humanos como computacionales. Requiere también un experto implementador de LLMs que sepa gestionar adecuadamente el equilibrio entre el fine-tuning y RAG.</p>
<hr class="docutils" />
<p>(Imagen de portada de i410hlr en Pixabay.)</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./writings"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="ia-aplicada-la-empresa-empoderada-por-la-ia.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">IA aplicada: la empresa empoderada por la IA</p>
      </div>
    </a>
    <a class="right-next"
       href="ley-de-ia-de-la-ue.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Ley de IA de la UE</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelos-de-referencia">Modelos de referencia</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelos-adaptados-fine-tuning">Modelos adaptados: fine-tuning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelos-alimentados-retrieval-augmented-generation-rag">Modelos alimentados: Retrieval-Augmented Generation (RAG)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comparativa-entre-rag-y-fine-tuning">Comparativa entre RAG y fine-tuning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones">Conclusiones</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Mikel Imaz, 2023-2025
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <p>
<a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
</p>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>